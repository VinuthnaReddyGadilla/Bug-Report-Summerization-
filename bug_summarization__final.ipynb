{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJUKc5Ok7kiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0cc4e34-e643-4969-e51a-291a624f8d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   BugNum                                            Summary\n",
            "0       1  please adjust the target milestone, so it does...\n",
            "1       2  build id: m20110210-1200 > build id: m20110210...\n",
            "2       3  build id: 2.0.1 one idea to resolve this probl...\n",
            "3       4  the workaround would require adopters to know ...\n",
            "4       5  it now modifies the list, releases the lock on...\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "#dataset = pd.read_csv(\"/content/drive/MyDrive/BugSum-master/excel sheet/scores.csv\")  # Replace \"bug_reports.csv\" with your file path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming df is your DataFrame containing the dataset\n",
        "# Placeholder parameters\n",
        "beam_size = 4  # Adjust based on experimentation\n",
        "word_limit = 150  # Adjust based on dataset and preference\n",
        "\n",
        "# Helper function to calculate word count\n",
        "def word_count(sentence):\n",
        "    return len(sentence.split())\n",
        "\n",
        "# Function to generate summary for a single bug report\n",
        "def beam_search_summary(group_df, beam_size, word_limit):\n",
        "    # Sort sentences within each bug report based on combined score in descending order\n",
        "    sorted_sentences = group_df.sort_values(by='Combined_Score', ascending=False)\n",
        "\n",
        "    # Initialize beam search variables\n",
        "    Lnew = []\n",
        "    LChosen = []  # This will hold the final selected sentences\n",
        "\n",
        "    # Start beam search\n",
        "    for _, row in sorted_sentences.iterrows():\n",
        "        sentence = row['Sentence']\n",
        "        combined_score = row['Combined_Score']\n",
        "\n",
        "        if len(LChosen) < beam_size and word_count(sentence) <= word_limit:\n",
        "            LChosen.append((sentence, combined_score))\n",
        "            word_limit -= word_count(sentence)  # Update word limit\n",
        "        else:\n",
        "            # Check if adding this sentence improves any existing choice in LChosen\n",
        "            for i, (chosen_sentence, chosen_score) in enumerate(LChosen):\n",
        "                if combined_score > chosen_score and word_count(sentence) <= word_limit:\n",
        "                    LChosen[i] = (sentence, combined_score)\n",
        "                    word_limit -= word_count(sentence)  # Update word limit\n",
        "                    break  # Exit loop after replacing to maintain beam size\n",
        "\n",
        "            # If not replaced, consider extending the search\n",
        "            if len(Lnew) < beam_size:\n",
        "                Lnew.append((sentence, combined_score))\n",
        "\n",
        "    # Select the set of sentences with the highest combined scores\n",
        "    final_sentences = sorted(LChosen + Lnew, key=lambda x: x[1], reverse=True)[:beam_size]\n",
        "\n",
        "    # Concatenate selected sentences to form the summary\n",
        "    summary = ' '.join([sentence for sentence, _ in final_sentences])\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/BugSum-master/excel sheet/scores.csv')\n",
        "\n",
        "# Apply the function to each bug report group\n",
        "df_grouped = df.groupby('BugNum').apply(lambda x: beam_search_summary(x, beam_size, word_limit))\n",
        "\n",
        "# Convert the series to a dataframe for better visualization\n",
        "summaries_df = df_grouped.reset_index(name='Summary')\n",
        "\n",
        "# Display the first few summaries\n",
        "print(summaries_df.head())\n",
        "\n",
        "\n",
        "# Ensure the 'summaries_df' DataFrame contains the summaries you want to save\n",
        "output_file_path = '/content/drive/MyDrive/BugSum-master/excel sheet/beam_bug_report_summaries.xlsx'  # Specify the path and file name for the output Excel file\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "summaries_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/BugSum-master/excel sheet/scores.csv')  # Ensure to update this path to your dataset location\n",
        "\n",
        "# Initialize BART tokenizer and model for summarization\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "def refine_summary_with_bart(selected_sentences):\n",
        "    # Combine selected sentences into a single text block\n",
        "    input_text = ' '.join(selected_sentences)\n",
        "    # Encode the text to tensor inputs\n",
        "    inputs = tokenizer.encode(\"summarize: \" + input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    # Generate summary output\n",
        "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Function to select top sentences based on combined scores and refine the summary with BART\n",
        "def generate_and_refine_summary(group_df, top_fraction=0.25):\n",
        "    # Select top N% sentences based on combined scores\n",
        "    num_sentences = max(1, int(len(group_df) * top_fraction))\n",
        "    top_sentences_df = group_df.sort_values(by='Combined_Score', ascending=False).head(num_sentences)\n",
        "\n",
        "    # Refine these sentences into a summary using BART\n",
        "    refined_summary = refine_summary_with_bart(top_sentences_df['Sentence'].tolist())\n",
        "    return refined_summary\n",
        "\n",
        "# Apply the function to each bug report group and generate refined summaries\n",
        "refined_summaries_df = df.groupby('BugNum').apply(generate_and_refine_summary).reset_index(name='Refined_Summary')\n",
        "\n",
        "# Save or display the refined summaries\n",
        "print(refined_summaries_df.head())\n",
        "\n",
        "# Ensure the 'summaries_df' DataFrame contains the summaries you want to save\n",
        "output_file_path = '/content/drive/MyDrive/BugSum-master/excel sheet/bart_bug_report_summaries.xlsx'  # Specify the path and file name for the output Excel file\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "refined_summaries_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYIdZOn8L-Dv",
        "outputId": "3e119e4c-973f-49bf-f1f7-115e9e75e33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   BugNum                                    Refined_Summary\n",
            "0       1  summarize: please adjust the target milestone,...\n",
            "1       2  Bug is similar to what bug# 297039 describes. ...\n",
            "2       3  A fix to the 2.0.1 and 3.0 streams. If any ser...\n",
            "3       4   java.io.file is used regardless of whether th...\n",
            "4       5  i will need the stack trace of both threads un...\n"
          ]
        }
      ]
    }
  ]
}