{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ButTN41tpA05",
        "outputId": "a1ec08b5-87a4-46bd-da94-adb806caed21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "! pip install rouge\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "import pandas as pd\n",
        "\n",
        "# Load your data\n",
        "beam_summaries_path = '/content/drive/MyDrive/BugSum-master/excel sheet/beam_bug_report_summaries.xlsx'\n",
        "bart_summaries_path = '/content/drive/MyDrive/BugSum-master/excel sheet/bart_bug_report_summaries.xlsx'\n",
        "\n",
        "beam_df = pd.read_excel(beam_summaries_path)\n",
        "bart_df = pd.read_excel(bart_summaries_path)\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "rouge = Rouge()\n",
        "\n",
        "# Prepare data for ROUGE calculation\n",
        "beam_summaries_dict = beam_df.set_index('BugNum')['Summary'].to_dict()\n",
        "bart_summaries_dict = bart_df.set_index('BugNum')['Refined_Summary'].to_dict()\n",
        "\n",
        "# Calculate ROUGE scores for each BART summary against the corresponding Beam summary as reference\n",
        "scores = []\n",
        "for bug_num, bart_summary in bart_summaries_dict.items():\n",
        "    if bug_num in beam_summaries_dict:\n",
        "        score = rouge.get_scores(bart_summary, beam_summaries_dict[bug_num], avg=True)\n",
        "        scores.append(score)\n",
        "\n",
        "# Aggregate average ROUGE scores\n",
        "average_scores = {'rouge-1': {'f': 0, 'p': 0, 'r': 0}, 'rouge-2': {'f': 0, 'p': 0, 'r': 0}, 'rouge-l': {'f': 0, 'p': 0, 'r': 0}}\n",
        "\n",
        "for score in scores:\n",
        "    for metric, values in score.items():\n",
        "        average_scores[metric]['f'] += values['f']\n",
        "        average_scores[metric]['p'] += values['p']\n",
        "        average_scores[metric]['r'] += values['r']\n",
        "\n",
        "num_scores = len(scores)\n",
        "for metric in average_scores:\n",
        "    average_scores[metric]['f'] /= num_scores\n",
        "    average_scores[metric]['p'] /= num_scores\n",
        "    average_scores[metric]['r'] /= num_scores\n",
        "\n",
        "print(\"Average ROUGE scores:\", average_scores)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Fp4Az_pEg6",
        "outputId": "4c8c0842-09e9-4797-add8-86dcd2eaa000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average ROUGE scores: {'rouge-1': {'f': 0.571995900881209, 'p': 0.6296426126954119, 'r': 0.5543852774138259}, 'rouge-2': {'f': 0.47795516153274625, 'p': 0.5394648758067383, 'r': 0.4586407406265393}, 'rouge-l': {'f': 0.5631154151487665, 'p': 0.6200688971989738, 'r': 0.5454635157549161}}\n"
          ]
        }
      ]
    }
  ]
}